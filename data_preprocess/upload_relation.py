from neo4j import GraphDatabase
import pandas as pd
import os

AURA_URI = "neo4j+s://1e53c988.databases.neo4j.io"
AURA_USER = "neo4j"
AURA_PASSWORD = "ZS-rBIrq-tN6CCQj6KpUksdPby16HFje9Fn_rvH_fLc"
RELATION_CSV_FOLDER = "dataKG/relations_csv"
BATCH_SIZE = 500 

class RelationImporter:
    def __init__(self, uri, user, password):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
        print("å·²è¿æ¥åˆ°Auraæ•°æ®åº“")

    def close(self):
        self.driver.close()

    def import_all_relations(self, folder_path):
        """å¯¼å…¥æ–‡ä»¶å¤¹å†…æ‰€æœ‰å…³ç³»CSVæ–‡ä»¶"""
        csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]
        
        if not csv_files:
            print("æ²¡æœ‰æ‰¾åˆ°CSVæ–‡ä»¶")
            return
        
        total_imported = 0
        failed_files = []
        
        for csv_file in csv_files:
            file_path = os.path.join(folder_path, csv_file)
            success, count = self.import_single_relation_file(file_path)
            
            if success:
                total_imported += count
            else:
                failed_files.append(csv_file)
        
        if failed_files:
            print(f"\n å¤±è´¥çš„æ–‡ä»¶:")
            for f in failed_files:
                print(f"  - {f}")
        
    
    def import_single_relation_file(self, csv_path):
        """å¯¼å…¥å•ä¸ªå…³ç³»CSVæ–‡ä»¶"""
        file_name = os.path.basename(csv_path)
        
        try:
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(csv_path, encoding='utf-8-sig')
            print(f"\nğŸ“¤ å¤„ç†æ–‡ä»¶: {file_name}")
            print(f"   æ€»å…³ç³»æ•°: {len(df)}")
            
            required_cols = ['subject_id', 'predicate', 'object_id']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                print(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
                return False, 0
                   
            property_cols = [col for col in df.columns if col not in required_cols]         
            
            with self.driver.session() as session:
                # æŸ¥è¯¢ç»“æ„ï¼šæŸ¥æ‰¾ä¸¤ä¸ªèŠ‚ç‚¹ï¼Œåˆ›å»ºå…³ç³»ï¼Œè®¾ç½®å…³ç³»å±æ€§
                query = """
                UNWIND $rows AS row
                MATCH (source {id: row.subject_id})
                MATCH (target {id: row.object_id})
                CALL apoc.create.relationship(
                    source, 
                    row.predicate,
                    apoc.map.removeKeys(row, ['subject_id', 'predicate', 'object_id']),
                    target
                ) YIELD rel
                RETURN count(rel)
                """
                
                # åˆ†æ‰¹å¯¼å…¥
                success_count = 0
                for i in range(0, len(df), BATCH_SIZE):
                    batch = df.iloc[i:i+BATCH_SIZE]
                    
                    # è½¬æ¢æ‰¹æ¬¡ä¸ºå­—å…¸åˆ—è¡¨
                    rows = batch.to_dict('records')
                    
                    try:
                        result = session.run(query, rows=rows)

                        summary = result.consume()
                        success_count += len(batch)
                        
                        batch_num = i // BATCH_SIZE + 1
                        total_batches = (len(df) + BATCH_SIZE - 1) // BATCH_SIZE
                        
                        if batch_num % 5 == 0 or batch_num == total_batches:
                            print(f"   è¿›åº¦: {min(i+BATCH_SIZE, len(df))}/{len(df)} è¡Œ")
                    
                    except Exception as batch_error:
                        print(f"   æ‰¹æ¬¡ {batch_num} å¤±è´¥: {batch_error}")
                        continue
                
                print(f" æˆåŠŸå¯¼å…¥: {success_count}/{len(df)} æ¡å…³ç³»")
                return True, success_count
                
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶ {file_name} å¤±è´¥: {e}")
            return False, 0
    
    
    def check_missing_nodes(self, csv_path):
        """æ£€æŸ¥å…³ç³»CSVä¸­å¼•ç”¨äº†å“ªäº›ä¸å­˜åœ¨äºæ•°æ®åº“ä¸­çš„èŠ‚ç‚¹"""
        try:
            df = pd.read_csv(csv_path, encoding='utf-8-sig')
            subject_ids = df['subject_id'].unique()
            object_ids = df['object_id'].unique()
            all_referenced_ids = set(list(subject_ids) + list(object_ids))
            
            with self.driver.session() as session:
                # æŸ¥è¯¢æ•°æ®åº“ä¸­å®é™…å­˜åœ¨çš„èŠ‚ç‚¹ID
                result = session.run("MATCH (n) RETURN n.id as node_id")
                existing_ids = set([record["node_id"] for record in result if record["node_id"]])
                
                # æ‰¾å‡ºç¼ºå¤±çš„ID
                missing_ids = all_referenced_ids - existing_ids
                
                if missing_ids:
                    print(f"\n å‘ç° {len(missing_ids)} ä¸ªæœªæ‰¾åˆ°çš„èŠ‚ç‚¹ID")
                    print(f"ç¤ºä¾‹ç¼ºå¤±ID: {list(missing_ids)[:10]}")
                    return False, missing_ids
                else:
                    print("æ‰€æœ‰å¼•ç”¨çš„èŠ‚ç‚¹IDåœ¨æ•°æ®åº“ä¸­éƒ½å­˜åœ¨")
                    return True, set()
                    
        except Exception as e:
            print(f"æ£€æŸ¥ç¼ºå¤±èŠ‚ç‚¹æ—¶å‡ºé”™: {e}")
            return False, set()

if __name__ == "__main__":
    importer = RelationImporter(AURA_URI, AURA_USER, AURA_PASSWORD)
    
    try:
        importer.import_all_relations(RELATION_CSV_FOLDER) 
    except Exception as e:
        print(f"\n å¯¼å…¥è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")

    finally:
        importer.close()